---
---

@string{aps = {American Physical Society,}}

@inproceedings{coling-2024-2,
  abbr      = {COLING-2024},
  title     = {Class-Incremental Few-Shot Event Detection},
  author    = {Zhao, Kailin 
               and Jin, Xiaolong 
               and Bai, Long 
               and Guo, Jiafeng 
               and Cheng, Xueqi},
  booktitle = {Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation},
  month     = may,
  year      = {2024}
}

@inproceedings{coling-2024-2,
  abbr      = {COLING-2024},
  title     = {Nested Event Extraction upon Pivot Element Recogniton},
  author    = {Ren, Weicheng 
               and Li, Zixuan 
               and Jin, Xiaolong 
               and Bai, Long 
               and Su, Miao 
               and Liu, Yantao 
               and Guan, Saiping 
               and Guo, Jiafeng 
               and Cheng, Xueqi},
  booktitle = {Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation},
  month     = may,
  year      = {2024}
}

@inproceedings{coling-2024-1,
  abbr      = {COLING-2024},
  title     = {Selective Temporal Knowledge Graph Reasoning},
  author    = {Hou, Zhongni 
               and Jin, Xiaolong 
               and Li, Zixuan 
               and Bai, Long 
               and Guo, Jiafeng 
               and Cheng, Xueqi},
  booktitle = {Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation},
  month     = may,
  year      = {2024}
}

@inproceedings{aaai-2024,
  abbr      = {AAAI-2024},
  title     = {Tree-of-Reasoning Question Decomposition for Complex Question Answering with Large Language Models},
  author    = {Zhang, Kun 
               and Zeng, Jiali
               and Meng, Fandong 
               and Wang, Yuanzhuo
               and Sun, Shiqi 
               and Bai, Long
               and Shen, Huawei 
               and Zhou, Jie},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  month     = feb,
  year      = {2024}
}

@inproceedings{emnlp-2023,
  abbr      = {EMNLP-2023},
  html      = {https://aclanthology.org/2023.findings-emnlp.77},
  title     = {Temporal Knowledge Graph Reasoning Based on N-tuple Modeling},
  author    = {Hou, Zhongni and
               Jin, Xiaolong and
               Li, Zixuan and
               Bai, Long and
               Guan, Saiping and
               Zeng, Yutao and
               Guo, Jiafeng and
               Cheng, Xueqi},
  abstract  = {Reasoning over Temporal Knowledge Graphs (TKGs) that predicts temporal facts (e.g., events) in the future is crucial for many applications. The temporal facts in existing TKGs only contain their core entities (i.e., the entities playing core roles therein) and formulate them as quadruples, i.e., (subject entity, predicate, object entity, timestamp). This formulation oversimplifies temporal facts and inevitably causes information loss. Therefore, we propose to describe a temporal fact more accurately as an n-tuple, containing not only its predicate and core entities, but also its auxiliary entities, as well as the roles of all entities. By so doing, TKGs are augmented to N-tuple Temporal Knowledge Graphs (N-TKGs). To conduct reasoning over N-TKGs, we further propose N-tuple Evolutional Network (NE-Net). It recurrently learns the evolutional representations of entities and predicates in temporal facts at different timestamps in the history via modeling the relations among those entities and predicates. Based on the learned representations, reasoning tasks at future timestamps can be realized via task-specific decoders. Experiment results on two newly built datasets demonstrate the superiority of N-TKG and the effectiveness of NE-Net.},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2023},
  month     = dec,
  year      = {2023}
}

@inproceedings{kdd-2023,
  abbr      = {KDD-2023},
  html      = {https://dl.acm.org/doi/abs/10.1145/3580305.3599273},
  title     = {CFGL-LCR: A Counterfactual Graph Learning Framework for Legal Case Retrieval},
  author    = {Zhang, Kun and 
               Chen, Chong and 
               Wang, Yuanzhuo and 
               Tian, Qi and 
               Bai, Long},
  abstract  = {Legal case retrieval, which aims to find relevant cases based on a short case description, serves as an important part of modern legal systems. Despite the success of existing retrieval methods based on Pretrained Language Models, there are still two issues in legal case retrieval that have not been well considered before. First, existing methods underestimate the semantics associations among legal elements, e.g., law articles and crimes, which played an essential role in legal case retrieval. These methods only adopt the pre-training language model to encode the whole legal case, instead of distinguishing different legal elements in the legal case. They randomly split a legal case into different segments, which may break the completeness of each legal element. Second, due to the difficulty in annotating the relevant labels of similar cases, legal case retrieval inevitably faces the problem of lacking training data. In this paper, we propose a counterfactual graph learning framework for legal case retrieval. Concretely, to overcome the above challenges, we transform the legal case document into a graph and model the semantics of the legal elements through a graph neural network. To alleviate the low resource and learn the causal relationship between the semantics of legal elements and relevance, a counterfactual data generator is designed to augment counterfactual data and enhance legal case representation. Extensive experiments based on two publicly available legal benchmarks demonstrate that our CFGL-LCR can significantly outperform previous state-of-the-art methods in legal case retrieval.},
  booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  month     = aug,
  year      = {2023}
}

@inproceedings{acl-2023,
  abbr      = {ACL-2023},
  html      = {https://aclanthology.org/2023.acl-long.610},
  title     = {Semantic Structure Enhanced Event Causality Identification},
  author    = {Hu, Zhilei  and
               Li, Zixuan  and
               Jin, Xiaolong  and
               Bai, Long  and
               Guan, Saiping  and
               Guo, Jiafeng  and
               Cheng, Xueqi},
  abstract  = {Event Causality Identification (ECI) aims to identify causal relations between events in unstructured texts. This is a very challenging task, because causal relations are usually expressed by implicit associations between events. Existing methods usually capture such associations by directly modeling the texts with pre-trained language models, which underestimate two kinds of semantic structures vital to the ECI task, namely, event-centric structure and event-associated structure. The former includes important semantic elements related to the events to describe them more precisely, while the latter contains semantic paths between two events to provide possible supports for ECI. In this paper, we study the implicit associations between events by modeling the above explicit semantic structures, and propose a Semantic Structure Integration model (SemSIn).It utilizes a GNN-based event aggregator to integrate the event-centric structure information, and employs an LSTM-based path aggregator to capture the event-associated structure information between two events. Experimental results on three widely used datasets show that SemSIn achieves significant improvements over baseline methods.},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2023}
}

@inproceedings{aaai-2023,
  abbr      = {AAAI-2023},
  html      = {https://ojs.aaai.org/index.php/AAAI/article/view/26478},
  code      = {https://github.com/waltbai/RePredictor},
  title     = {Rich Event Modeling for Script Event Prediction},
  author    = {Bai, Long and Guan, Saiping and Li, Zixuan and Guo, Jiafeng and Jin, Xiaolong and Cheng, Xueqi},
  abstract  = {Script is a kind of structured knowledge extracted from texts, which contains a sequence of events. Based on such knowledge, script event prediction aims to predict the subsequent event. To do so, two aspects should be considered for events, namely, event description (i.e., what the events should contain) and event encoding (i.e., how they should be encoded). Most existing methods describe an event by a verb together with a few core arguments (i.e., subject, object, and indirect object), which are not precise enough. In addition, existing event encoders are limited to a fixed number of arguments, which are not flexible enough to deal with extra information. Thus, in this paper, we propose the Rich Event Prediction (REP) framework for script event prediction. Fundamentally, it is based on the proposed rich event description, which enriches the existing ones with three kinds of important information, namely, the senses of verbs, extra semantic roles, and types of participants. REP contains an event extractor to extract such information from texts. Based on the extracted rich information, a predictor then selects the most probable subsequent event. The core component of the predictor is a transformer-based event encoder that integrates the above information flexibly. Experimental results on the widely used Gigaword Corpus show the effectiveness of the proposed framework.},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  month     = jun,
  year      = {2023}
}

@inproceedings{emnlp-2022-2,
  abbr      = {EMNLP-2022},
  html      = {https://aclanthology.org/2022.findings-emnlp.467},
  title     = {Knowledge-Enhanced Self-Supervised Prototypical Network for Few-Shot Event Detection},
  author    = {Zhao, Kailin  and
               Jin, Xiaolong  and
               Bai, Long  and
               Guo, Jiafeng  and
               Cheng, Xueqi},
  abstract  = {Prototypical network based joint methods have attracted much attention in few-shot event detection, which carry out event detection in a unified sequence tagging framework. However, these methods suffer from the inaccurate prototype representation problem, due to two main reasons: the number of instances for calculating prototypes is limited; And, they do not well capture the relationships among event prototypes. To deal with this problem, we propose a Knowledge-Enhanced self-supervised Prototypical Network, called KE-PN, for few-shot event detection. KE-PN adopts hybrid rules, which can automatically align event types to an external knowledge base, i.e., FrameNet, to obtain more instances. It proposes a self-supervised learning method to filter out noisy data from enhanced instances. KE-PN is further equipped with an auxiliary event type relationship classification module, which injects the relationship information into representations of event prototypes. Extensive experiments on three benchmark datasets, i.e., FewEvent, MAVEN, and ACE2005 demonstrate the state-of-the-art performance of KE-PN.},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2022},
  month     = dec,
  year      = {2022}
}

@inproceedings{emnlp-2022-1,
  abbr      = {EMNLP-2022},
  html      = {https://aclanthology.org/2022.findings-emnlp.542},
  code      = {https://github.com/Lee-zix/HiSMatch},
  title     = {{H}i{SM}atch: Historical Structure Matching based Temporal Knowledge Graph Reasoning},
  author    = {Li, Zixuan  and
               Hou, Zhongni  and
               Guan, Saiping  and
               Jin, Xiaolong  and
               Peng, Weihua  and
               Bai, Long  and
               Lyu, Yajuan  and
               Li, Wei  and
               Guo, Jiafeng  and
               Cheng, Xueqi},
  abstract  = {A Temporal Knowledge Graph (TKG) is a sequence of KGs with respective timestamps, which adopts quadruples in the form of (subject, relation, object, timestamp) to describe dynamic facts. TKG reasoning has facilitated many real-world applications via answering such queries as (query entity, query relation, ?, future timestamp) about future. This is actually a matching task between a query and candidate entities based on their historical structures, which reflect behavioral trends of the entities at different timestamps. In addition, recent KGs provide background knowledge of all the entities, which is also helpful for the matching. Thus, in this paper, we propose the Historical Structure Matching (HiSMatch) model. It applies two structure encoders to capture the semantic information contained in the historical structures of the query and candidate entities. Besides, it adopts another encoder to integrate the background knowledge into the model. TKG reasoning experiments on six benchmark datasets demonstrate the significant improvement of the proposed HiSMatch model, with up to 5.6% performance improvement in MRR, compared to the state-of-the-art baselines.},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2022},
  month     = dec,
  year      = {2022}
}

@inproceedings{coling-2022,
  abbr      = {COLING-2022},
  html      = {https://aclanthology.org/2022.coling-1.533},
  title     = {Meta-{CQG}: A Meta-Learning Framework for Complex Question Generation over Knowledge Bases},
  author    = {Zhang, Kun  and
               Qiu, Yunqi  and
               Wang, Yuanzhuo  and
               Bai, Long  and
               Li, Wei  and
               Jiang, Xuhui  and
               Shen, Huawei  and
               Cheng, Xueqi},
  abstract  = {Complex question generation over knowledge bases (KB) aims to generate natural language questions involving multiple KB relations or functional constraints. Existing methods train one encoder-decoder-based model to fit all questions. However, such a one-size-fits-all strategy may not perform well since complex questions exhibit an uneven distribution in many dimensions, such as question types, involved KB relations, and query structures, resulting in insufficient learning for long-tailed samples under different dimensions. To address this problem, we propose a meta-learning framework for complex question generation. The meta-trained generator can acquire universal and transferable meta-knowledge and quickly adapt to long-tailed samples through a few most related training samples. To retrieve similar samples for each input query, we design a self-supervised graph retriever to learn distributed representations for samples, and contrastive learning is leveraged to improve the learned representations. We conduct experiments on both WebQuestionsSP and ComplexWebQuestion, and results on long-tailed samples of different dimensions have been significantly improved, which demonstrates the effectiveness of the proposed framework.},
  booktitle = {Proceedings of the 29th International Conference on Computational Linguistics},
  month     = oct,
  year      = {2022}
}

@article{aes-2022,
  abbr    = {AES-2022},
  title   = {面向知识库问答的问句语义解析研究综述},
  author  = {仇韫琦 and 王元卓 and 白龙 and 尹芷仪 and 沈华伟 and 白硕},
  journal = {电子学报},
  month   = sep,
  year    = {2022}
}

@article{tkde-2022,
  abbr     = {TKDE-2022},
  html     = {https://ieeexplore.ieee.org/abstract/document/9792280},
  title    = {What is Event Knowledge Graph: A Survey},
  author   = {Guan, Saiping and Cheng, Xueqi and Bai, Long and Zhang, Fujun and Li, Zixuan and Zeng, Yutao and Jin, Xiaolong and Guo, Jiafeng},
  abstract = {Besides entity-centric knowledge, usually organized as Knowledge Graph (KG), events are also an essential kind of knowledge in the world, which trigger the spring up of event-centric knowledge representation form like Event KG (EKG). It plays an increasingly important role in many downstream applications, such as search, question-answering, recommendation, financial quantitative investments, and text generation. This paper provides a comprehensive survey of EKG from history, ontology, instance, and application views. Specifically, to characterize EKG thoroughly, we focus on its history, definition, schema induction, acquisition, related representative graphs/systems, and applications. The development processes and trends are studied therein. We further summarize prospective directions to facilitate future research on EKG.},
  journal  = {IEEE Transactions on Knowledge and Data Engineering},
  month    = jun,
  year     = {2022}
}

@inproceedings{acl-2022,
  abbr      = {ACL-2022},
  html      = {https://aclanthology.org/2022.acl-short.32},
  title     = {Complex Evolutional Pattern Learning for Temporal Knowledge Graph Reasoning},
  author    = {Li, Zixuan  and
               Guan, Saiping  and
               Jin, Xiaolong  and
               Peng, Weihua  and
               Lyu, Yajuan  and
               Zhu, Yong  and
               Bai, Long  and
               Li, Wei  and
               Guo, Jiafeng  and
               Cheng, Xueqi},
  abstract  = {A Temporal Knowledge Graph (TKG) is a sequence of KGs corresponding to different timestamps. TKG reasoning aims to predict potential facts in the future given the historical KG sequences. One key of this task is to mine and understand evolutional patterns of facts from these sequences. The evolutional patterns are complex in two aspects, length-diversity and time-variability. Existing models for TKG reasoning focus on modeling fact sequences of a fixed length, which cannot discover complex evolutional patterns that vary in length. Furthermore, these models are all trained offline, which cannot well adapt to the changes of evolutional patterns from then on. Thus, we propose a new model, called Complex Evolutional Network (CEN), which uses a length-aware Convolutional Neural Network (CNN) to handle evolutional patterns of different lengths via an easy-to-difficult curriculum learning strategy. Besides, we propose to learn the model under the online setting so that it can adapt to the changes of evolutional patterns over time. Extensive experiments demonstrate that CEN obtains substantial performance improvement under both the traditional offline and the proposed online settings.},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  month     = may,
  year      = {2022}
}

@inproceedings{emnlp-2021,
  abbr      = {EMNLP-2021},
  html      = {https://aclanthology.org/2021.emnlp-main.777},
  code      = {https://github.com/waltbai/MCPredictor},
  title     = {Integrating Deep Event-Level and Script-Level Information for Script Event Prediction},
  author    = {Bai, Long  and
               Guan, Saiping  and
               Guo, Jiafeng  and
               Li, Zixuan  and
               Jin, Xiaolong  and
               Cheng, Xueqi},
  abstract  = {Scripts are structured sequences of events together with the participants, which are extracted from the texts. Script event prediction aims to predict the subsequent event given the historical events in the script. Two kinds of information facilitate this task, namely, the event-level information and the script-level information. At the event level, existing studies view an event as a verb with its participants, while neglecting other useful properties, such as the state of the participants. At the script level, most existing studies only consider a single event sequence corresponding to one common protagonist. In this paper, we propose a Transformer-based model, called MCPredictor, which integrates deep event-level and script-level information for script event prediction. At the event level, MCPredictor utilizes the rich information in the text to obtain more comprehensive event semantic representations. At the script-level, it considers multiple event sequences corresponding to different participants of the subsequent event. The experimental results on the widely-used New York Times corpus demonstrate the effectiveness and superiority of the proposed model.},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2021}
}

@inproceedings{acl-2021,
  abbr      = {ACL-2021},
  html      = {https://aclanthology.org/2021.findings-acl.412},
  title     = {Rule-Aware Reinforcement Learning for Knowledge Graph Reasoning},
  author    = {Hou, Zhongni  and
               Jin, Xiaolong  and
               Li, Zixuan  and
               Bai, Long},
  abstract  = {Multi-hop reasoning is an effective and explainable approach to predicting missing facts in Knowledge Graphs (KGs). It usually adopts the Reinforcement Learning (RL) framework and searches over the KG to find an evidential path. However, due to the large exploration space, the RL-based model struggles with the serious sparse reward problem and needs to make a lot of trials. Moreover, its exploration can be biased towards spurious paths that coincidentally lead to correct answers. To solve both problems, we propose a simple but effective RL-based method called RARL (Rule-Aware RL). It injects high quality symbolic rules into the model's reasoning process and employs partially random beam search, which can not only increase the probability of paths getting rewards, but also alleviate the impact of spurious paths. Experimental results show that it outperforms existing multi-hop methods in terms of Hit@1 and MRR.},
  booktitle = {Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  month     = aug,
  year      = {2021}
}

@inproceedings{cikm-2020,
  abbr      = {CIKM-2020},
  html      = {https://dl.acm.org/doi/abs/10.1145/3340531.3411888},
  title     = {Hierarchical Query Graph Generation for Complex Question Answering over Knowledge Graph},
  author    = {Qiu, Yunqi and Zhang, Kun and Wang, Yuanzhuo and Jin, Xiaolong and Bai, Long and Guan, Saiping and Cheng, Xueqi},
  abstract  = {Knowledge Graph Question Answering aims to automatically answer natural language questions via well-structured relation information between entities stored in knowledge graphs. When faced with a complex question with compositional semantics, query graph generation is a practical semantic parsing-based method. But existing works rely on heuristic rules with limited coverage, making them impractical on more complex questions. This paper proposes a Director-Actor-Critic framework to overcome these challenges. Through options over a Markov Decision Process, query graph generation is formulated as a hierarchical decision problem. The Director determines which types of triples the query graph needs, the Actor generates corresponding triples by choosing nodes and edges, and the Critic calculates the semantic similarity between the generated triples and the given questions. Moreover, to train from weak supervision, we base the framework on hierarchical Reinforcement Learning with intrinsic motivation. To accelerate the training process, we pre-train the Critic with high-reward trajectories generated by hand-crafted rules, and leverage curriculum learning to gradually increase the complexity of questions during query graph generation. Extensive experiments conducted over widely-used benchmark datasets demonstrate the effectiveness of the proposed framework.},
  booktitle = {Proceedings of the 29th ACM International Conference on Information \& Knowledge Management},
  month     = oct,
  year      = {2020}
}

@inproceedings{acml-2020,
  abbr      = {ACML-2020},
  html      = {https://proceedings.mlr.press/v129/deng20a.html},
  title     = {Bidirectional Dependency-Guided Attention for Relation Extraction},
  author    = {Deng, Xingchen and Zhang, Lei and Fan, Yixing and Bai, Long and Guo, Jiafeng and Wang, Pengfei},
  abstract  = {The dependency relation between words in the sentence is critical for the relation extraction. Existing methods often utilize the dependencies accompanied with various pruning strategies, thus suffer from the loss of detailed semantic information.In order to exploit dependency structure more effectively, we propose a novel bidirectional dependency-guided attention model. The main idea is to use a top-down attention as well as a bottom-up attention to fully capture the dependencies from different granularity. Specifically, the bottom-up attention aims to model the local semantics from the subtree of each node, while the top-down attention is to model the global semantics from the ancestor nodes. Moreover, we employ a label embedding component to attend the contextual features, which are extracted by the dependency-guided attention. Overall, the proposed model is fully attention-based which make it easy for parallel computing. Experiment results on TACRED dataset and SemEval 2010 Task 8 dataset show that our model outperforms existing dependency based models as well as the powerful pretraining model. Moreover, the proposed model achieves the state-of-the-art performance on TACRED dataset.},
  booktitle = {Proceedings of the 12th Asian Conference on Machine Learning},
  month     = nov,
  year      = {2020}
}

@inproceedings{aaai-2020,
  abbr      = {AAAI-2020},
  html      = {https://ojs.aaai.org/index.php/AAAI/article/view/7147},
  title     = {Entity Type Enhanced Neural Model for Distantly Supervised Relation Extraction (Student Abstract)},
  author    = {Bai, Long and Jin, Xiaolong and Zhuang, Chuanzhi and Cheng, Xueqi},
  abstract  = {Distantly Supervised Relation Extraction (DSRE) has been widely studied, since it can automatically extract relations from very large corpora. However, existing DSRE methods only use little semantic information about entities, such as the information of entity type. Thus, in this paper, we propose a method for integrating entity type information into a neural network based DSRE model. It also adopts two attention mechanisms, namely, sentence attention and type attention. The former selects the representative sentences for a sentence bag, while the latter selects appropriate type information for entities. Experimental comparison with existing methods on a benchmark dataset demonstrates its merits.},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  month     = apr,
  year      = {2020}
}

@article{jcip-2019-1,
  abbr    = {JCIP-2019},
  title   = {基于深度学习的关系抽取研究综述},
  author  = {庄传志 and 靳小龙 and 朱伟建 and 刘静伟 and 白龙 and 程学旗},
  journal = {中文信息学报},
  month   = dec,
  year    = {2019}
}

@article{jcip-2019-2,
  abbr    = {JCIP-2019},
  title   = {基于远程监督的关系抽取研究综述},
  author  = {白龙 and 靳小龙 and 席鹏弼 and 程学旗},
  journal = {中文信息学报},
  month   = oct,
  year    = {2019}
}
